{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1vPkIZTvmXRA",
   "metadata": {
    "id": "1vPkIZTvmXRA"
   },
   "source": [
    "# Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2c7c197",
   "metadata": {
    "id": "e2c7c197"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers --quiet\n",
    "!pip install evaluate --quiet\n",
    "!pip install --upgrade sentencepiece --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SRZg6uTFmmXf",
   "metadata": {
    "id": "SRZg6uTFmmXf"
   },
   "source": [
    "# Instantiate T5 Models & Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244e1f59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "244e1f59",
    "outputId": "25d3e644-c2c1-4af9-ffde-5cac6f8eaade"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "baseline_checkpoint = \"t5-large\"\n",
    "finetuned_checkpoint = \"/Users/mikelu/extssd/git/ucb_mids_W266_project/t5-large-lyric-generation/\"\n",
    "\n",
    "max_length = 512\n",
    "\n",
    "baseline_model = T5ForConditionalGeneration.from_pretrained(\n",
    "    baseline_checkpoint\n",
    ")\n",
    "baseline_tokenizer = T5Tokenizer.from_pretrained(\n",
    "    baseline_checkpoint,\n",
    "    model_max_length=max_length\n",
    ")\n",
    "\n",
    "finetuned_model = T5ForConditionalGeneration.from_pretrained(\n",
    "    finetuned_checkpoint\n",
    ")\n",
    "finetuned_tokenizer = T5Tokenizer.from_pretrained(\n",
    "    finetuned_checkpoint,\n",
    "    model_max_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PvvwxNJ6msiN",
   "metadata": {
    "id": "PvvwxNJ6msiN"
   },
   "source": [
    "# Load Test Data\n",
    "\n",
    "Each record represents a song, with lyrics stored as multi-line text in the \"lyrics\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7a53f5e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "7a53f5e0",
    "outputId": "0f1e9dbe-4275-4ccb-9171-bf4b406a97f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5465961</td>\n",
       "      <td>Be Where We Are</td>\n",
       "      <td>country</td>\n",
       "      <td>Julia Cole</td>\n",
       "      <td>2021</td>\n",
       "      <td>Cash only bar with a juke box\\nPut a dollar in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1781039</td>\n",
       "      <td>Only Daddy That’ll Walk the Line</td>\n",
       "      <td>country</td>\n",
       "      <td>Waylon Jennings</td>\n",
       "      <td>1968</td>\n",
       "      <td>Everybody knows you've been stepping on my toe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>672903</td>\n",
       "      <td>I Cant Be Your Sweetheart</td>\n",
       "      <td>country</td>\n",
       "      <td>The Carter Family</td>\n",
       "      <td>1998</td>\n",
       "      <td>Last night I told my heart's love\\nAll under t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>934006</td>\n",
       "      <td>Fire Line Road</td>\n",
       "      <td>country</td>\n",
       "      <td>James McMurtry</td>\n",
       "      <td>2008</td>\n",
       "      <td>My name is Alice Walker, they never told me wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962549</td>\n",
       "      <td>Run Around</td>\n",
       "      <td>country</td>\n",
       "      <td>Austin Lucas</td>\n",
       "      <td>2011</td>\n",
       "      <td>You want answers; I don't have any\\nJust more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>2391145</td>\n",
       "      <td>Life</td>\n",
       "      <td>rap</td>\n",
       "      <td>Criss Lyric</td>\n",
       "      <td>2015</td>\n",
       "      <td>My niggas all about cash\\nMy niggas tryna rack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>7456521</td>\n",
       "      <td>Dumptruck</td>\n",
       "      <td>rap</td>\n",
       "      <td>Full Tac</td>\n",
       "      <td>2021</td>\n",
       "      <td>Dump, dump, dump, dump, dump\\nDump it\\nBack it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>2412522</td>\n",
       "      <td>Real Nigga Files</td>\n",
       "      <td>rap</td>\n",
       "      <td>Kodak Black</td>\n",
       "      <td>2015</td>\n",
       "      <td>Real nigga files (Hell yeah)\\nProject files (Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>7799558</td>\n",
       "      <td>Science Project</td>\n",
       "      <td>rap</td>\n",
       "      <td>Fly Anakin</td>\n",
       "      <td>2018</td>\n",
       "      <td>My bitch a choosy lover never fuck without a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>4155478</td>\n",
       "      <td>TNGR Intro</td>\n",
       "      <td>rap</td>\n",
       "      <td>KAYRXN</td>\n",
       "      <td>2018</td>\n",
       "      <td>Yea Yea Yea Yea\\nYea Yea Yea Yea\\nWoe, Woe\\nYe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                             title      tag             artist  \\\n",
       "0      5465961                   Be Where We Are  country         Julia Cole   \n",
       "1      1781039  Only Daddy That’ll Walk the Line  country    Waylon Jennings   \n",
       "2       672903         I Cant Be Your Sweetheart  country  The Carter Family   \n",
       "3       934006                    Fire Line Road  country     James McMurtry   \n",
       "4      1962549                        Run Around  country       Austin Lucas   \n",
       "...        ...                               ...      ...                ...   \n",
       "19995  2391145                              Life      rap        Criss Lyric   \n",
       "19996  7456521                         Dumptruck      rap           Full Tac   \n",
       "19997  2412522                  Real Nigga Files      rap        Kodak Black   \n",
       "19998  7799558                   Science Project      rap         Fly Anakin   \n",
       "19999  4155478                        TNGR Intro      rap             KAYRXN   \n",
       "\n",
       "       year                                             lyrics  \n",
       "0      2021  Cash only bar with a juke box\\nPut a dollar in...  \n",
       "1      1968  Everybody knows you've been stepping on my toe...  \n",
       "2      1998  Last night I told my heart's love\\nAll under t...  \n",
       "3      2008  My name is Alice Walker, they never told me wh...  \n",
       "4      2011  You want answers; I don't have any\\nJust more ...  \n",
       "...     ...                                                ...  \n",
       "19995  2015  My niggas all about cash\\nMy niggas tryna rack...  \n",
       "19996  2021  Dump, dump, dump, dump, dump\\nDump it\\nBack it...  \n",
       "19997  2015  Real nigga files (Hell yeah)\\nProject files (Y...  \n",
       "19998  2018  My bitch a choosy lover never fuck without a r...  \n",
       "19999  2018  Yea Yea Yea Yea\\nYea Yea Yea Yea\\nWoe, Woe\\nYe...  \n",
       "\n",
       "[20000 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"test_no_markers.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P3__F3QNnFBY",
   "metadata": {
    "id": "P3__F3QNnFBY"
   },
   "source": [
    "# Generate Lyrics\n",
    "\n",
    "For each song in the test dataset:\n",
    "\n",
    "1. Construct a prompt consisting of a task prefix and up to 8 lines of lyrics\n",
    "2. Tokenize the prompt\n",
    "3. Have the model generate tokens representing the next line of song lyrics\n",
    "4. Repeat steps 1-3 for the finetuned model.\n",
    "5. Store results in a dictionary (to be converted to a DataFrame later)\n",
    "\n",
    "The reference for each model prediction is the next line from the song's lyrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a313b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "c7a313b6",
    "outputId": "cf2a4639-2220-4c80-b3b3-71e9855d8bc8",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "output_dict = [None] * len(df)\n",
    "\n",
    "max_input_lyrics = 8        # number of lines of the song's lyrics to pass to the model\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "\n",
    "    lyric_lines = row.lyrics.split(\"\\n\")\n",
    "\n",
    "    # if the song has fewer than max_input_lyrics,\n",
    "    # then use all but the last line of the lyrics\n",
    "    # in the input prompt\n",
    "    num_lyric_lines = max_input_lyrics\n",
    "    if len(lyric_lines) < max_input_lyrics + 1:\n",
    "         num_lyric_lines = len(lyric_lines) - 1\n",
    "\n",
    "    # calculate the maximum number of words contained\n",
    "    # in each line of the song's lyrics -- we'll pass\n",
    "    # this to the model as the maximum number of new\n",
    "    # tokens to generate\n",
    "    num_words = [len(x.split(\" \")) for x in lyric_lines]\n",
    "    max_words = int(np.max([20, np.max(num_words)]))\n",
    "\n",
    "    snippet = \"\\n\".join(lyric_lines[0:num_lyric_lines])\n",
    "    reference = lyric_lines[num_lyric_lines]\n",
    "\n",
    "    # the baseline T5 model has a task prefix of \"summarize:\"\n",
    "    # for text generation\n",
    "    baseline_prompt = \"summarize: \" + snippet\n",
    "\n",
    "    # tokenize the input\n",
    "    baseline_input_tokens = baseline_tokenizer(\n",
    "        baseline_prompt,\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # generate the output tokens\n",
    "    baseline_output_tokens = baseline_model.generate(\n",
    "        baseline_input_tokens[\"input_ids\"],\n",
    "        max_new_tokens=max_words,\n",
    "        num_beams=2,\n",
    "        repetition_penalty=1.2\n",
    "    )\n",
    "\n",
    "    # convert the output to a text string\n",
    "    baseline_output = \"\".join(\n",
    "        baseline_tokenizer.batch_decode(\n",
    "            baseline_output_tokens,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # repeat the steps above for the finetuned model,\n",
    "    # which uses a different task prefix\n",
    "    finetuned_prompt = \"write next line for: \" + snippet\n",
    "\n",
    "    finetuned_input_tokens = finetuned_tokenizer(\n",
    "        finetuned_prompt,\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    finetuned_output_tokens = finetuned_model.generate(\n",
    "        finetuned_input_tokens[\"input_ids\"],\n",
    "        max_new_tokens=max_words,\n",
    "        num_beams=2,\n",
    "        repetition_penalty=1.2\n",
    "    )\n",
    "\n",
    "    finetuned_output = \"\".join(\n",
    "        finetuned_tokenizer.batch_decode(\n",
    "            finetuned_output_tokens,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # store the results to the output dictionary array\n",
    "    output_dict[i] = {\n",
    "        \"song_id\" : row.id,\n",
    "        \"input\" : snippet,\n",
    "        \"reference\" : reference,\n",
    "        \"baseline_output\" : baseline_output,\n",
    "        \"finetuned_output\" : finetuned_output\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GM6emnMfoxeD",
   "metadata": {
    "id": "GM6emnMfoxeD"
   },
   "source": [
    "# Convert Output Dictionary to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0965e47a",
   "metadata": {
    "id": "0965e47a",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(output_dict)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5jY7shXVo1xh",
   "metadata": {
    "id": "5jY7shXVo1xh"
   },
   "source": [
    "# Calculate rouge and bleu Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0459560a",
   "metadata": {
    "id": "0459560a"
   },
   "outputs": [],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "baseline_rouge_scores = rouge.compute(\n",
    "    predictions=results_df[\"baseline_output\"],\n",
    "    references=results_df[\"reference\"]\n",
    ")\n",
    "\n",
    "baseline_bleu_scores = bleu.compute(\n",
    "    predictions=results_df[\"baseline_output\"],\n",
    "    references=results_df[\"reference\"]\n",
    ")\n",
    "\n",
    "finetuned_rouge_scores = rouge.compute(\n",
    "    predictions=results_df[\"finetuned_output\"],\n",
    "    references=results_df[\"reference\"]\n",
    ")\n",
    "\n",
    "finetuned_bleu_scores = bleu.compute(\n",
    "    predictions=results_df[\"finetuned_output\"],\n",
    "    references=results_df[\"reference\"]\n",
    ")\n",
    "\n",
    "score_dict = [None] * 2\n",
    "score_dict[0] = {\n",
    "    \"model\" : \"baseline\",\n",
    "    \"bleu\" : baseline_bleu_scores[\"bleu\"],\n",
    "    \"rouge1\" : baseline_rouge_scores[\"rouge1\"],\n",
    "    \"rouge2\" : baseline_rouge_scores[\"rouge2\"],\n",
    "    \"rougeL\" : baseline_rouge_scores[\"rougeL\"]\n",
    "}\n",
    "score_dict[1] = {\n",
    "    \"model\" : \"finetuned\",\n",
    "    \"bleu\" : finetuned_bleu_scores[\"bleu\"],\n",
    "    \"rouge1\" : finetuned_rouge_scores[\"rouge1\"],\n",
    "    \"rouge2\" : finetuned_rouge_scores[\"rouge2\"],\n",
    "    \"rougeL\" : finetuned_rouge_scores[\"rougeL\"]\n",
    "}\n",
    "\n",
    "score_df = pd.DataFrame(score_dict)\n",
    "score_df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
