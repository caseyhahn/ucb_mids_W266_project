{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1vPkIZTvmXRA",
   "metadata": {
    "id": "1vPkIZTvmXRA"
   },
   "source": [
    "# Install and Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2c7c197",
   "metadata": {
    "id": "e2c7c197"
   },
   "outputs": [],
   "source": [
    "!pip install --upgrade transformers --quiet\n",
    "!pip install evaluate --quiet\n",
    "!pip install --upgrade sentencepiece --quiet\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import evaluate\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "SRZg6uTFmmXf",
   "metadata": {
    "id": "SRZg6uTFmmXf"
   },
   "source": [
    "# Instantiate T5 Models & Tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "244e1f59",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "244e1f59",
    "outputId": "25d3e644-c2c1-4af9-ffde-5cac6f8eaade"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thouroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "baseline_checkpoint = \"t5-large\"\n",
    "finetuned_checkpoint = \"/Users/mikelu/extssd/git/ucb_mids_W266_project/t5-large-lyric-generation/\"\n",
    "\n",
    "max_length = 512\n",
    "\n",
    "baseline_model = T5ForConditionalGeneration.from_pretrained(\n",
    "    baseline_checkpoint\n",
    ")\n",
    "baseline_tokenizer = T5Tokenizer.from_pretrained(\n",
    "    baseline_checkpoint,\n",
    "    model_max_length=max_length\n",
    ")\n",
    "\n",
    "finetuned_model = T5ForConditionalGeneration.from_pretrained(\n",
    "    finetuned_checkpoint\n",
    ")\n",
    "finetuned_tokenizer = T5Tokenizer.from_pretrained(\n",
    "    finetuned_checkpoint,\n",
    "    model_max_length=max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "PvvwxNJ6msiN",
   "metadata": {
    "id": "PvvwxNJ6msiN"
   },
   "source": [
    "# Load Test Data\n",
    "\n",
    "Each record represents a song, with lyrics stored as multi-line text in the \"lyrics\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a53f5e0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "7a53f5e0",
    "outputId": "0f1e9dbe-4275-4ccb-9171-bf4b406a97f1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5465961</td>\n",
       "      <td>Be Where We Are</td>\n",
       "      <td>country</td>\n",
       "      <td>Julia Cole</td>\n",
       "      <td>2021</td>\n",
       "      <td>Cash only bar with a juke box\\nPut a dollar in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1781039</td>\n",
       "      <td>Only Daddy That’ll Walk the Line</td>\n",
       "      <td>country</td>\n",
       "      <td>Waylon Jennings</td>\n",
       "      <td>1968</td>\n",
       "      <td>Everybody knows you've been stepping on my toe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>672903</td>\n",
       "      <td>I Cant Be Your Sweetheart</td>\n",
       "      <td>country</td>\n",
       "      <td>The Carter Family</td>\n",
       "      <td>1998</td>\n",
       "      <td>Last night I told my heart's love\\nAll under t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>934006</td>\n",
       "      <td>Fire Line Road</td>\n",
       "      <td>country</td>\n",
       "      <td>James McMurtry</td>\n",
       "      <td>2008</td>\n",
       "      <td>My name is Alice Walker, they never told me wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1962549</td>\n",
       "      <td>Run Around</td>\n",
       "      <td>country</td>\n",
       "      <td>Austin Lucas</td>\n",
       "      <td>2011</td>\n",
       "      <td>You want answers; I don't have any\\nJust more ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19995</th>\n",
       "      <td>2391145</td>\n",
       "      <td>Life</td>\n",
       "      <td>rap</td>\n",
       "      <td>Criss Lyric</td>\n",
       "      <td>2015</td>\n",
       "      <td>My niggas all about cash\\nMy niggas tryna rack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19996</th>\n",
       "      <td>7456521</td>\n",
       "      <td>Dumptruck</td>\n",
       "      <td>rap</td>\n",
       "      <td>Full Tac</td>\n",
       "      <td>2021</td>\n",
       "      <td>Dump, dump, dump, dump, dump\\nDump it\\nBack it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19997</th>\n",
       "      <td>2412522</td>\n",
       "      <td>Real Nigga Files</td>\n",
       "      <td>rap</td>\n",
       "      <td>Kodak Black</td>\n",
       "      <td>2015</td>\n",
       "      <td>Real nigga files (Hell yeah)\\nProject files (Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19998</th>\n",
       "      <td>7799558</td>\n",
       "      <td>Science Project</td>\n",
       "      <td>rap</td>\n",
       "      <td>Fly Anakin</td>\n",
       "      <td>2018</td>\n",
       "      <td>My bitch a choosy lover never fuck without a r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19999</th>\n",
       "      <td>4155478</td>\n",
       "      <td>TNGR Intro</td>\n",
       "      <td>rap</td>\n",
       "      <td>KAYRXN</td>\n",
       "      <td>2018</td>\n",
       "      <td>Yea Yea Yea Yea\\nYea Yea Yea Yea\\nWoe, Woe\\nYe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                             title      tag             artist  \\\n",
       "0      5465961                   Be Where We Are  country         Julia Cole   \n",
       "1      1781039  Only Daddy That’ll Walk the Line  country    Waylon Jennings   \n",
       "2       672903         I Cant Be Your Sweetheart  country  The Carter Family   \n",
       "3       934006                    Fire Line Road  country     James McMurtry   \n",
       "4      1962549                        Run Around  country       Austin Lucas   \n",
       "...        ...                               ...      ...                ...   \n",
       "19995  2391145                              Life      rap        Criss Lyric   \n",
       "19996  7456521                         Dumptruck      rap           Full Tac   \n",
       "19997  2412522                  Real Nigga Files      rap        Kodak Black   \n",
       "19998  7799558                   Science Project      rap         Fly Anakin   \n",
       "19999  4155478                        TNGR Intro      rap             KAYRXN   \n",
       "\n",
       "       year                                             lyrics  \n",
       "0      2021  Cash only bar with a juke box\\nPut a dollar in...  \n",
       "1      1968  Everybody knows you've been stepping on my toe...  \n",
       "2      1998  Last night I told my heart's love\\nAll under t...  \n",
       "3      2008  My name is Alice Walker, they never told me wh...  \n",
       "4      2011  You want answers; I don't have any\\nJust more ...  \n",
       "...     ...                                                ...  \n",
       "19995  2015  My niggas all about cash\\nMy niggas tryna rack...  \n",
       "19996  2021  Dump, dump, dump, dump, dump\\nDump it\\nBack it...  \n",
       "19997  2015  Real nigga files (Hell yeah)\\nProject files (Y...  \n",
       "19998  2018  My bitch a choosy lover never fuck without a r...  \n",
       "19999  2018  Yea Yea Yea Yea\\nYea Yea Yea Yea\\nWoe, Woe\\nYe...  \n",
       "\n",
       "[20000 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"test_no_markers.csv\")\n",
    "df.drop(columns=[\"Unnamed: 0\"], inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "49728da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rap</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rb</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rock</th>\n",
       "      <td>5000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id\n",
       "tag          \n",
       "country  5000\n",
       "rap      5000\n",
       "rb       5000\n",
       "rock     5000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"tag\", \"id\"]].groupby(\"tag\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8814630c",
   "metadata": {},
   "source": [
    "20,000 records is too big of a dataset to run the model against (too time consuming). So we'll take a stratified sample of 250 songs from each of the 4 genres."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b222acae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>tag</th>\n",
       "      <th>artist</th>\n",
       "      <th>year</th>\n",
       "      <th>lyrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6728186</td>\n",
       "      <td>Live and Forget</td>\n",
       "      <td>country</td>\n",
       "      <td>FRIEDRIICH</td>\n",
       "      <td>2020</td>\n",
       "      <td>Pick one of my random memories\\nI can precisel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5057485</td>\n",
       "      <td>October</td>\n",
       "      <td>country</td>\n",
       "      <td>Kody West</td>\n",
       "      <td>2019</td>\n",
       "      <td>It's October\\nThe leaves are falling down, fal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7128594</td>\n",
       "      <td>Something Goods Gonna Happen</td>\n",
       "      <td>country</td>\n",
       "      <td>The Wolfe Brothers</td>\n",
       "      <td>2021</td>\n",
       "      <td>Well, you don't like my smoking\\nYou don't lik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194843</td>\n",
       "      <td>Fine Line</td>\n",
       "      <td>country</td>\n",
       "      <td>Little Big Town</td>\n",
       "      <td>2007</td>\n",
       "      <td>Completely complacent\\nSo excitedly vacant\\nI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7764202</td>\n",
       "      <td>Best Of Me</td>\n",
       "      <td>country</td>\n",
       "      <td>Josh Ramsay</td>\n",
       "      <td>2022</td>\n",
       "      <td>Feels like home doesn’t look right\\nThe truth ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>5636396</td>\n",
       "      <td>State Of Mind</td>\n",
       "      <td>rock</td>\n",
       "      <td>Silence the Crow</td>\n",
       "      <td>2020</td>\n",
       "      <td>Take your hands off me\\nI'm beyond your touch\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>7333221</td>\n",
       "      <td>Rising Seas</td>\n",
       "      <td>rock</td>\n",
       "      <td>Midnight Oil</td>\n",
       "      <td>2021</td>\n",
       "      <td>Every child put down your toys\\nAnd come insid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1024796</td>\n",
       "      <td>Lights Camera Action</td>\n",
       "      <td>rock</td>\n",
       "      <td>Nonpoint</td>\n",
       "      <td>2012</td>\n",
       "      <td>Light up the room with a little more light\\nI ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>6785137</td>\n",
       "      <td>Whats Going On</td>\n",
       "      <td>rock</td>\n",
       "      <td>Metal Orizon</td>\n",
       "      <td>2001</td>\n",
       "      <td>I don’t what the world is coming to\\nEverythin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>3540265</td>\n",
       "      <td>Something Here Demo</td>\n",
       "      <td>rock</td>\n",
       "      <td>Day Wave</td>\n",
       "      <td>2017</td>\n",
       "      <td>I'm laying around\\nMy head on the ground\\nI fe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          id                         title      tag              artist  year  \\\n",
       "0    6728186               Live and Forget  country          FRIEDRIICH  2020   \n",
       "1    5057485                       October  country           Kody West  2019   \n",
       "2    7128594  Something Goods Gonna Happen  country  The Wolfe Brothers  2021   \n",
       "3     194843                     Fine Line  country     Little Big Town  2007   \n",
       "4    7764202                    Best Of Me  country         Josh Ramsay  2022   \n",
       "..       ...                           ...      ...                 ...   ...   \n",
       "995  5636396                 State Of Mind     rock    Silence the Crow  2020   \n",
       "996  7333221                   Rising Seas     rock        Midnight Oil  2021   \n",
       "997  1024796          Lights Camera Action     rock            Nonpoint  2012   \n",
       "998  6785137                Whats Going On     rock        Metal Orizon  2001   \n",
       "999  3540265           Something Here Demo     rock            Day Wave  2017   \n",
       "\n",
       "                                                lyrics  \n",
       "0    Pick one of my random memories\\nI can precisel...  \n",
       "1    It's October\\nThe leaves are falling down, fal...  \n",
       "2    Well, you don't like my smoking\\nYou don't lik...  \n",
       "3    Completely complacent\\nSo excitedly vacant\\nI ...  \n",
       "4    Feels like home doesn’t look right\\nThe truth ...  \n",
       "..                                                 ...  \n",
       "995  Take your hands off me\\nI'm beyond your touch\\...  \n",
       "996  Every child put down your toys\\nAnd come insid...  \n",
       "997  Light up the room with a little more light\\nI ...  \n",
       "998  I don’t what the world is coming to\\nEverythin...  \n",
       "999  I'm laying around\\nMy head on the ground\\nI fe...  \n",
       "\n",
       "[1000 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.groupby(\"tag\", as_index=False, group_keys=False).apply(lambda x: x.sample(250, random_state=1868))\n",
    "df = df.reset_index(drop=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4bd7ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tag</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>country</th>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rap</th>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rb</th>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rock</th>\n",
       "      <td>250</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id\n",
       "tag         \n",
       "country  250\n",
       "rap      250\n",
       "rb       250\n",
       "rock     250"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"tag\", \"id\"]].groupby(\"tag\").count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "P3__F3QNnFBY",
   "metadata": {
    "id": "P3__F3QNnFBY"
   },
   "source": [
    "# Generate Lyrics\n",
    "\n",
    "For each song in the test dataset:\n",
    "\n",
    "1. Construct a prompt consisting of a task prefix and up to 8 lines of lyrics\n",
    "2. Tokenize the prompt\n",
    "3. Have the model generate tokens representing the next line of song lyrics\n",
    "4. Repeat steps 1-3 for the finetuned model.\n",
    "5. Store results in a dictionary (to be converted to a DataFrame later)\n",
    "\n",
    "The reference for each model prediction is the next line from the song's lyrics.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c7a313b6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "c7a313b6",
    "outputId": "cf2a4639-2220-4c80-b3b3-71e9855d8bc8",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 1000\n",
      "1 of 1000\n",
      "2 of 1000\n",
      "3 of 1000\n",
      "4 of 1000\n",
      "5 of 1000\n",
      "6 of 1000\n",
      "7 of 1000\n",
      "8 of 1000\n",
      "9 of 1000\n",
      "10 of 1000\n",
      "11 of 1000\n",
      "12 of 1000\n",
      "13 of 1000\n",
      "14 of 1000\n",
      "15 of 1000\n",
      "16 of 1000\n",
      "17 of 1000\n",
      "18 of 1000\n",
      "19 of 1000\n",
      "20 of 1000\n",
      "21 of 1000\n",
      "22 of 1000\n",
      "23 of 1000\n",
      "24 of 1000\n",
      "25 of 1000\n",
      "26 of 1000\n",
      "27 of 1000\n",
      "28 of 1000\n",
      "29 of 1000\n",
      "30 of 1000\n",
      "31 of 1000\n",
      "32 of 1000\n",
      "33 of 1000\n",
      "34 of 1000\n",
      "35 of 1000\n",
      "36 of 1000\n",
      "37 of 1000\n",
      "38 of 1000\n",
      "39 of 1000\n",
      "40 of 1000\n",
      "41 of 1000\n",
      "42 of 1000\n",
      "43 of 1000\n",
      "44 of 1000\n",
      "45 of 1000\n",
      "46 of 1000\n",
      "47 of 1000\n",
      "48 of 1000\n",
      "49 of 1000\n",
      "50 of 1000\n",
      "51 of 1000\n",
      "52 of 1000\n",
      "53 of 1000\n",
      "54 of 1000\n",
      "55 of 1000\n",
      "56 of 1000\n",
      "57 of 1000\n",
      "58 of 1000\n",
      "59 of 1000\n",
      "60 of 1000\n",
      "61 of 1000\n",
      "62 of 1000\n",
      "63 of 1000\n",
      "64 of 1000\n",
      "65 of 1000\n",
      "66 of 1000\n",
      "67 of 1000\n",
      "68 of 1000\n",
      "69 of 1000\n",
      "70 of 1000\n",
      "71 of 1000\n",
      "72 of 1000\n",
      "73 of 1000\n",
      "74 of 1000\n",
      "75 of 1000\n",
      "76 of 1000\n",
      "77 of 1000\n",
      "78 of 1000\n",
      "79 of 1000\n",
      "80 of 1000\n",
      "81 of 1000\n",
      "82 of 1000\n",
      "83 of 1000\n",
      "84 of 1000\n",
      "85 of 1000\n",
      "86 of 1000\n",
      "87 of 1000\n",
      "88 of 1000\n",
      "89 of 1000\n",
      "90 of 1000\n",
      "91 of 1000\n",
      "92 of 1000\n",
      "93 of 1000\n",
      "94 of 1000\n",
      "95 of 1000\n",
      "96 of 1000\n",
      "97 of 1000\n",
      "98 of 1000\n",
      "99 of 1000\n",
      "100 of 1000\n",
      "101 of 1000\n",
      "102 of 1000\n",
      "103 of 1000\n",
      "104 of 1000\n",
      "105 of 1000\n",
      "106 of 1000\n",
      "107 of 1000\n",
      "108 of 1000\n",
      "109 of 1000\n",
      "110 of 1000\n",
      "111 of 1000\n",
      "112 of 1000\n",
      "113 of 1000\n",
      "114 of 1000\n",
      "115 of 1000\n",
      "116 of 1000\n",
      "117 of 1000\n",
      "118 of 1000\n",
      "119 of 1000\n",
      "120 of 1000\n",
      "121 of 1000\n",
      "122 of 1000\n",
      "123 of 1000\n",
      "124 of 1000\n",
      "125 of 1000\n",
      "126 of 1000\n",
      "127 of 1000\n",
      "128 of 1000\n",
      "129 of 1000\n",
      "130 of 1000\n",
      "131 of 1000\n",
      "132 of 1000\n",
      "133 of 1000\n",
      "134 of 1000\n",
      "135 of 1000\n",
      "136 of 1000\n",
      "137 of 1000\n",
      "138 of 1000\n",
      "139 of 1000\n",
      "140 of 1000\n",
      "141 of 1000\n",
      "142 of 1000\n",
      "143 of 1000\n",
      "144 of 1000\n",
      "145 of 1000\n",
      "146 of 1000\n",
      "147 of 1000\n",
      "148 of 1000\n",
      "149 of 1000\n",
      "150 of 1000\n",
      "151 of 1000\n",
      "152 of 1000\n",
      "153 of 1000\n",
      "154 of 1000\n",
      "155 of 1000\n",
      "156 of 1000\n",
      "157 of 1000\n",
      "158 of 1000\n",
      "159 of 1000\n",
      "160 of 1000\n",
      "161 of 1000\n",
      "162 of 1000\n",
      "163 of 1000\n",
      "164 of 1000\n",
      "165 of 1000\n",
      "166 of 1000\n",
      "167 of 1000\n",
      "168 of 1000\n",
      "169 of 1000\n",
      "170 of 1000\n",
      "171 of 1000\n",
      "172 of 1000\n",
      "173 of 1000\n",
      "174 of 1000\n",
      "175 of 1000\n",
      "176 of 1000\n",
      "177 of 1000\n",
      "178 of 1000\n",
      "179 of 1000\n",
      "180 of 1000\n",
      "181 of 1000\n",
      "182 of 1000\n",
      "183 of 1000\n",
      "184 of 1000\n",
      "185 of 1000\n",
      "186 of 1000\n",
      "187 of 1000\n",
      "188 of 1000\n",
      "189 of 1000\n",
      "190 of 1000\n",
      "191 of 1000\n",
      "192 of 1000\n",
      "193 of 1000\n",
      "194 of 1000\n",
      "195 of 1000\n",
      "196 of 1000\n",
      "197 of 1000\n",
      "198 of 1000\n",
      "199 of 1000\n",
      "200 of 1000\n",
      "201 of 1000\n",
      "202 of 1000\n",
      "203 of 1000\n",
      "204 of 1000\n",
      "205 of 1000\n",
      "206 of 1000\n",
      "207 of 1000\n",
      "208 of 1000\n",
      "209 of 1000\n",
      "210 of 1000\n",
      "211 of 1000\n",
      "212 of 1000\n",
      "213 of 1000\n",
      "214 of 1000\n",
      "215 of 1000\n",
      "216 of 1000\n",
      "217 of 1000\n",
      "218 of 1000\n",
      "219 of 1000\n",
      "220 of 1000\n",
      "221 of 1000\n",
      "222 of 1000\n",
      "223 of 1000\n",
      "224 of 1000\n",
      "225 of 1000\n",
      "226 of 1000\n",
      "227 of 1000\n",
      "228 of 1000\n",
      "229 of 1000\n",
      "230 of 1000\n",
      "231 of 1000\n",
      "232 of 1000\n",
      "233 of 1000\n",
      "234 of 1000\n",
      "235 of 1000\n",
      "236 of 1000\n",
      "237 of 1000\n",
      "238 of 1000\n",
      "239 of 1000\n",
      "240 of 1000\n",
      "241 of 1000\n",
      "242 of 1000\n",
      "243 of 1000\n",
      "244 of 1000\n",
      "245 of 1000\n",
      "246 of 1000\n",
      "247 of 1000\n",
      "248 of 1000\n",
      "249 of 1000\n",
      "250 of 1000\n",
      "251 of 1000\n",
      "252 of 1000\n",
      "253 of 1000\n",
      "254 of 1000\n",
      "255 of 1000\n",
      "256 of 1000\n",
      "257 of 1000\n",
      "258 of 1000\n",
      "259 of 1000\n",
      "260 of 1000\n",
      "261 of 1000\n",
      "262 of 1000\n",
      "263 of 1000\n",
      "264 of 1000\n",
      "265 of 1000\n",
      "266 of 1000\n",
      "267 of 1000\n",
      "268 of 1000\n",
      "269 of 1000\n",
      "270 of 1000\n",
      "271 of 1000\n",
      "272 of 1000\n",
      "273 of 1000\n",
      "274 of 1000\n",
      "275 of 1000\n",
      "276 of 1000\n",
      "277 of 1000\n",
      "278 of 1000\n",
      "279 of 1000\n",
      "280 of 1000\n",
      "281 of 1000\n",
      "282 of 1000\n",
      "283 of 1000\n",
      "284 of 1000\n",
      "285 of 1000\n",
      "286 of 1000\n",
      "287 of 1000\n",
      "288 of 1000\n",
      "289 of 1000\n",
      "290 of 1000\n",
      "291 of 1000\n",
      "292 of 1000\n",
      "293 of 1000\n",
      "294 of 1000\n",
      "295 of 1000\n",
      "296 of 1000\n",
      "297 of 1000\n",
      "298 of 1000\n",
      "299 of 1000\n",
      "300 of 1000\n",
      "301 of 1000\n",
      "302 of 1000\n",
      "303 of 1000\n",
      "304 of 1000\n",
      "305 of 1000\n",
      "306 of 1000\n",
      "307 of 1000\n",
      "308 of 1000\n",
      "309 of 1000\n",
      "310 of 1000\n",
      "311 of 1000\n",
      "312 of 1000\n",
      "313 of 1000\n",
      "314 of 1000\n",
      "315 of 1000\n",
      "316 of 1000\n",
      "317 of 1000\n",
      "318 of 1000\n",
      "319 of 1000\n",
      "320 of 1000\n",
      "321 of 1000\n",
      "322 of 1000\n",
      "323 of 1000\n",
      "324 of 1000\n",
      "325 of 1000\n",
      "326 of 1000\n",
      "327 of 1000\n",
      "328 of 1000\n",
      "329 of 1000\n",
      "330 of 1000\n",
      "331 of 1000\n",
      "332 of 1000\n",
      "333 of 1000\n",
      "334 of 1000\n",
      "335 of 1000\n",
      "336 of 1000\n",
      "337 of 1000\n",
      "338 of 1000\n",
      "339 of 1000\n",
      "340 of 1000\n",
      "341 of 1000\n",
      "342 of 1000\n",
      "343 of 1000\n",
      "344 of 1000\n",
      "345 of 1000\n",
      "346 of 1000\n",
      "347 of 1000\n",
      "348 of 1000\n",
      "349 of 1000\n",
      "350 of 1000\n",
      "351 of 1000\n",
      "352 of 1000\n",
      "353 of 1000\n",
      "354 of 1000\n",
      "355 of 1000\n",
      "356 of 1000\n",
      "357 of 1000\n",
      "358 of 1000\n",
      "359 of 1000\n",
      "360 of 1000\n",
      "361 of 1000\n",
      "362 of 1000\n",
      "363 of 1000\n",
      "364 of 1000\n",
      "365 of 1000\n",
      "366 of 1000\n",
      "367 of 1000\n",
      "368 of 1000\n",
      "369 of 1000\n",
      "370 of 1000\n",
      "371 of 1000\n",
      "372 of 1000\n",
      "373 of 1000\n",
      "374 of 1000\n",
      "375 of 1000\n",
      "376 of 1000\n",
      "377 of 1000\n",
      "378 of 1000\n",
      "379 of 1000\n",
      "380 of 1000\n",
      "381 of 1000\n",
      "382 of 1000\n",
      "383 of 1000\n",
      "384 of 1000\n",
      "385 of 1000\n",
      "386 of 1000\n",
      "387 of 1000\n",
      "388 of 1000\n",
      "389 of 1000\n",
      "390 of 1000\n",
      "391 of 1000\n",
      "392 of 1000\n",
      "393 of 1000\n",
      "394 of 1000\n",
      "395 of 1000\n",
      "396 of 1000\n",
      "397 of 1000\n",
      "398 of 1000\n",
      "399 of 1000\n",
      "400 of 1000\n",
      "401 of 1000\n",
      "402 of 1000\n",
      "403 of 1000\n",
      "404 of 1000\n",
      "405 of 1000\n",
      "406 of 1000\n",
      "407 of 1000\n",
      "408 of 1000\n",
      "409 of 1000\n",
      "410 of 1000\n",
      "411 of 1000\n",
      "412 of 1000\n",
      "413 of 1000\n",
      "414 of 1000\n",
      "415 of 1000\n",
      "416 of 1000\n",
      "417 of 1000\n",
      "418 of 1000\n",
      "419 of 1000\n",
      "420 of 1000\n",
      "421 of 1000\n",
      "422 of 1000\n",
      "423 of 1000\n",
      "424 of 1000\n",
      "425 of 1000\n",
      "426 of 1000\n",
      "427 of 1000\n",
      "428 of 1000\n",
      "429 of 1000\n",
      "430 of 1000\n",
      "431 of 1000\n",
      "432 of 1000\n",
      "433 of 1000\n",
      "434 of 1000\n",
      "435 of 1000\n",
      "436 of 1000\n",
      "437 of 1000\n",
      "438 of 1000\n",
      "439 of 1000\n",
      "440 of 1000\n",
      "441 of 1000\n",
      "442 of 1000\n",
      "443 of 1000\n",
      "444 of 1000\n",
      "445 of 1000\n",
      "446 of 1000\n",
      "447 of 1000\n",
      "448 of 1000\n",
      "449 of 1000\n",
      "450 of 1000\n",
      "451 of 1000\n",
      "452 of 1000\n",
      "453 of 1000\n",
      "454 of 1000\n",
      "455 of 1000\n",
      "456 of 1000\n",
      "457 of 1000\n",
      "458 of 1000\n",
      "459 of 1000\n",
      "460 of 1000\n",
      "461 of 1000\n",
      "462 of 1000\n",
      "463 of 1000\n",
      "464 of 1000\n",
      "465 of 1000\n",
      "466 of 1000\n",
      "467 of 1000\n",
      "468 of 1000\n",
      "469 of 1000\n",
      "470 of 1000\n",
      "471 of 1000\n",
      "472 of 1000\n",
      "473 of 1000\n",
      "474 of 1000\n",
      "475 of 1000\n",
      "476 of 1000\n",
      "477 of 1000\n",
      "478 of 1000\n",
      "479 of 1000\n",
      "480 of 1000\n",
      "481 of 1000\n",
      "482 of 1000\n",
      "483 of 1000\n",
      "484 of 1000\n",
      "485 of 1000\n",
      "486 of 1000\n",
      "487 of 1000\n",
      "488 of 1000\n",
      "489 of 1000\n",
      "490 of 1000\n",
      "491 of 1000\n",
      "492 of 1000\n",
      "493 of 1000\n",
      "494 of 1000\n",
      "495 of 1000\n",
      "496 of 1000\n",
      "497 of 1000\n",
      "498 of 1000\n",
      "499 of 1000\n",
      "500 of 1000\n",
      "501 of 1000\n",
      "502 of 1000\n",
      "503 of 1000\n",
      "504 of 1000\n",
      "505 of 1000\n",
      "506 of 1000\n",
      "507 of 1000\n",
      "508 of 1000\n",
      "509 of 1000\n",
      "510 of 1000\n",
      "511 of 1000\n",
      "512 of 1000\n",
      "513 of 1000\n",
      "514 of 1000\n",
      "515 of 1000\n",
      "516 of 1000\n",
      "517 of 1000\n",
      "518 of 1000\n",
      "519 of 1000\n",
      "520 of 1000\n",
      "521 of 1000\n",
      "522 of 1000\n",
      "523 of 1000\n",
      "524 of 1000\n",
      "525 of 1000\n",
      "526 of 1000\n",
      "527 of 1000\n",
      "528 of 1000\n",
      "529 of 1000\n",
      "530 of 1000\n",
      "531 of 1000\n",
      "532 of 1000\n",
      "533 of 1000\n",
      "534 of 1000\n",
      "535 of 1000\n",
      "536 of 1000\n",
      "537 of 1000\n",
      "538 of 1000\n",
      "539 of 1000\n",
      "540 of 1000\n",
      "541 of 1000\n",
      "542 of 1000\n",
      "543 of 1000\n",
      "544 of 1000\n",
      "545 of 1000\n",
      "546 of 1000\n",
      "547 of 1000\n",
      "548 of 1000\n",
      "549 of 1000\n",
      "550 of 1000\n",
      "551 of 1000\n",
      "552 of 1000\n",
      "553 of 1000\n",
      "554 of 1000\n",
      "555 of 1000\n",
      "556 of 1000\n",
      "557 of 1000\n",
      "558 of 1000\n",
      "559 of 1000\n",
      "560 of 1000\n",
      "561 of 1000\n",
      "562 of 1000\n",
      "563 of 1000\n",
      "564 of 1000\n",
      "565 of 1000\n",
      "566 of 1000\n",
      "567 of 1000\n",
      "568 of 1000\n",
      "569 of 1000\n",
      "570 of 1000\n",
      "571 of 1000\n",
      "572 of 1000\n",
      "573 of 1000\n",
      "574 of 1000\n",
      "575 of 1000\n",
      "576 of 1000\n",
      "577 of 1000\n",
      "578 of 1000\n",
      "579 of 1000\n",
      "580 of 1000\n",
      "581 of 1000\n",
      "582 of 1000\n",
      "583 of 1000\n",
      "584 of 1000\n",
      "585 of 1000\n",
      "586 of 1000\n",
      "587 of 1000\n",
      "588 of 1000\n",
      "589 of 1000\n",
      "590 of 1000\n",
      "591 of 1000\n",
      "592 of 1000\n",
      "593 of 1000\n",
      "594 of 1000\n",
      "595 of 1000\n",
      "596 of 1000\n",
      "597 of 1000\n",
      "598 of 1000\n",
      "599 of 1000\n",
      "600 of 1000\n",
      "601 of 1000\n",
      "602 of 1000\n",
      "603 of 1000\n",
      "604 of 1000\n",
      "605 of 1000\n",
      "606 of 1000\n",
      "607 of 1000\n",
      "608 of 1000\n",
      "609 of 1000\n",
      "610 of 1000\n",
      "611 of 1000\n",
      "612 of 1000\n",
      "613 of 1000\n",
      "614 of 1000\n",
      "615 of 1000\n",
      "616 of 1000\n",
      "617 of 1000\n",
      "618 of 1000\n",
      "619 of 1000\n",
      "620 of 1000\n",
      "621 of 1000\n",
      "622 of 1000\n",
      "623 of 1000\n",
      "624 of 1000\n",
      "625 of 1000\n",
      "626 of 1000\n",
      "627 of 1000\n",
      "628 of 1000\n",
      "629 of 1000\n",
      "630 of 1000\n",
      "631 of 1000\n",
      "632 of 1000\n",
      "633 of 1000\n",
      "634 of 1000\n",
      "635 of 1000\n",
      "636 of 1000\n",
      "637 of 1000\n",
      "638 of 1000\n",
      "639 of 1000\n",
      "640 of 1000\n",
      "641 of 1000\n",
      "642 of 1000\n",
      "643 of 1000\n",
      "644 of 1000\n",
      "645 of 1000\n",
      "646 of 1000\n",
      "647 of 1000\n",
      "648 of 1000\n",
      "649 of 1000\n",
      "650 of 1000\n",
      "651 of 1000\n",
      "652 of 1000\n",
      "653 of 1000\n",
      "654 of 1000\n",
      "655 of 1000\n",
      "656 of 1000\n",
      "657 of 1000\n",
      "658 of 1000\n",
      "659 of 1000\n",
      "660 of 1000\n",
      "661 of 1000\n",
      "662 of 1000\n",
      "663 of 1000\n",
      "664 of 1000\n",
      "665 of 1000\n",
      "666 of 1000\n",
      "667 of 1000\n",
      "668 of 1000\n",
      "669 of 1000\n",
      "670 of 1000\n",
      "671 of 1000\n",
      "672 of 1000\n",
      "673 of 1000\n",
      "674 of 1000\n",
      "675 of 1000\n",
      "676 of 1000\n",
      "677 of 1000\n",
      "678 of 1000\n",
      "679 of 1000\n",
      "680 of 1000\n",
      "681 of 1000\n",
      "682 of 1000\n",
      "683 of 1000\n",
      "684 of 1000\n",
      "685 of 1000\n",
      "686 of 1000\n",
      "687 of 1000\n",
      "688 of 1000\n",
      "689 of 1000\n",
      "690 of 1000\n",
      "691 of 1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "692 of 1000\n",
      "693 of 1000\n",
      "694 of 1000\n",
      "695 of 1000\n",
      "696 of 1000\n",
      "697 of 1000\n",
      "698 of 1000\n",
      "699 of 1000\n",
      "700 of 1000\n",
      "701 of 1000\n",
      "702 of 1000\n",
      "703 of 1000\n",
      "704 of 1000\n",
      "705 of 1000\n",
      "706 of 1000\n",
      "707 of 1000\n",
      "708 of 1000\n",
      "709 of 1000\n",
      "710 of 1000\n",
      "711 of 1000\n",
      "712 of 1000\n",
      "713 of 1000\n",
      "714 of 1000\n",
      "715 of 1000\n",
      "716 of 1000\n",
      "717 of 1000\n",
      "718 of 1000\n",
      "719 of 1000\n",
      "720 of 1000\n",
      "721 of 1000\n",
      "722 of 1000\n",
      "723 of 1000\n",
      "724 of 1000\n",
      "725 of 1000\n",
      "726 of 1000\n",
      "727 of 1000\n",
      "728 of 1000\n",
      "729 of 1000\n",
      "730 of 1000\n",
      "731 of 1000\n",
      "732 of 1000\n",
      "733 of 1000\n",
      "734 of 1000\n",
      "735 of 1000\n",
      "736 of 1000\n",
      "737 of 1000\n",
      "738 of 1000\n",
      "739 of 1000\n",
      "740 of 1000\n",
      "741 of 1000\n",
      "742 of 1000\n",
      "743 of 1000\n",
      "744 of 1000\n",
      "745 of 1000\n",
      "746 of 1000\n",
      "747 of 1000\n",
      "748 of 1000\n",
      "749 of 1000\n",
      "750 of 1000\n",
      "751 of 1000\n",
      "752 of 1000\n",
      "753 of 1000\n",
      "754 of 1000\n",
      "755 of 1000\n",
      "756 of 1000\n",
      "757 of 1000\n",
      "758 of 1000\n",
      "759 of 1000\n",
      "760 of 1000\n",
      "761 of 1000\n",
      "762 of 1000\n",
      "763 of 1000\n",
      "764 of 1000\n",
      "765 of 1000\n",
      "766 of 1000\n",
      "767 of 1000\n",
      "768 of 1000\n",
      "769 of 1000\n",
      "770 of 1000\n",
      "771 of 1000\n",
      "772 of 1000\n",
      "773 of 1000\n",
      "774 of 1000\n",
      "775 of 1000\n",
      "776 of 1000\n",
      "777 of 1000\n",
      "778 of 1000\n",
      "779 of 1000\n",
      "780 of 1000\n",
      "781 of 1000\n",
      "782 of 1000\n",
      "783 of 1000\n",
      "784 of 1000\n",
      "785 of 1000\n",
      "786 of 1000\n",
      "787 of 1000\n",
      "788 of 1000\n",
      "789 of 1000\n",
      "790 of 1000\n",
      "791 of 1000\n",
      "792 of 1000\n",
      "793 of 1000\n",
      "794 of 1000\n",
      "795 of 1000\n",
      "796 of 1000\n",
      "797 of 1000\n",
      "798 of 1000\n",
      "799 of 1000\n",
      "800 of 1000\n",
      "801 of 1000\n",
      "802 of 1000\n",
      "803 of 1000\n",
      "804 of 1000\n",
      "805 of 1000\n",
      "806 of 1000\n",
      "807 of 1000\n",
      "808 of 1000\n",
      "809 of 1000\n",
      "810 of 1000\n",
      "811 of 1000\n",
      "812 of 1000\n",
      "813 of 1000\n",
      "814 of 1000\n",
      "815 of 1000\n",
      "816 of 1000\n",
      "817 of 1000\n",
      "818 of 1000\n",
      "819 of 1000\n",
      "820 of 1000\n",
      "821 of 1000\n",
      "822 of 1000\n",
      "823 of 1000\n",
      "824 of 1000\n",
      "825 of 1000\n",
      "826 of 1000\n",
      "827 of 1000\n",
      "828 of 1000\n",
      "829 of 1000\n",
      "830 of 1000\n",
      "831 of 1000\n",
      "832 of 1000\n",
      "833 of 1000\n",
      "834 of 1000\n",
      "835 of 1000\n",
      "836 of 1000\n",
      "837 of 1000\n",
      "838 of 1000\n",
      "839 of 1000\n",
      "840 of 1000\n",
      "841 of 1000\n",
      "842 of 1000\n",
      "843 of 1000\n",
      "844 of 1000\n",
      "845 of 1000\n",
      "846 of 1000\n",
      "847 of 1000\n",
      "848 of 1000\n",
      "849 of 1000\n",
      "850 of 1000\n",
      "851 of 1000\n",
      "852 of 1000\n",
      "853 of 1000\n",
      "854 of 1000\n",
      "855 of 1000\n",
      "856 of 1000\n",
      "857 of 1000\n",
      "858 of 1000\n",
      "859 of 1000\n",
      "860 of 1000\n",
      "861 of 1000\n",
      "862 of 1000\n",
      "863 of 1000\n",
      "864 of 1000\n",
      "865 of 1000\n",
      "866 of 1000\n",
      "867 of 1000\n",
      "868 of 1000\n",
      "869 of 1000\n",
      "870 of 1000\n",
      "871 of 1000\n",
      "872 of 1000\n",
      "873 of 1000\n",
      "874 of 1000\n",
      "875 of 1000\n",
      "876 of 1000\n",
      "877 of 1000\n",
      "878 of 1000\n",
      "879 of 1000\n",
      "880 of 1000\n",
      "881 of 1000\n",
      "882 of 1000\n",
      "883 of 1000\n",
      "884 of 1000\n",
      "885 of 1000\n",
      "886 of 1000\n",
      "887 of 1000\n",
      "888 of 1000\n",
      "889 of 1000\n",
      "890 of 1000\n",
      "891 of 1000\n",
      "892 of 1000\n",
      "893 of 1000\n",
      "894 of 1000\n",
      "895 of 1000\n",
      "896 of 1000\n",
      "897 of 1000\n",
      "898 of 1000\n",
      "899 of 1000\n",
      "900 of 1000\n",
      "901 of 1000\n",
      "902 of 1000\n",
      "903 of 1000\n",
      "904 of 1000\n",
      "905 of 1000\n",
      "906 of 1000\n",
      "907 of 1000\n",
      "908 of 1000\n",
      "909 of 1000\n",
      "910 of 1000\n",
      "911 of 1000\n",
      "912 of 1000\n",
      "913 of 1000\n",
      "914 of 1000\n",
      "915 of 1000\n",
      "916 of 1000\n",
      "917 of 1000\n",
      "918 of 1000\n",
      "919 of 1000\n",
      "920 of 1000\n",
      "921 of 1000\n",
      "922 of 1000\n",
      "923 of 1000\n",
      "924 of 1000\n",
      "925 of 1000\n",
      "926 of 1000\n",
      "927 of 1000\n",
      "928 of 1000\n",
      "929 of 1000\n",
      "930 of 1000\n",
      "931 of 1000\n",
      "932 of 1000\n",
      "933 of 1000\n",
      "934 of 1000\n",
      "935 of 1000\n",
      "936 of 1000\n",
      "937 of 1000\n",
      "938 of 1000\n",
      "939 of 1000\n",
      "940 of 1000\n",
      "941 of 1000\n",
      "942 of 1000\n",
      "943 of 1000\n",
      "944 of 1000\n",
      "945 of 1000\n",
      "946 of 1000\n",
      "947 of 1000\n",
      "948 of 1000\n",
      "949 of 1000\n",
      "950 of 1000\n",
      "951 of 1000\n",
      "952 of 1000\n",
      "953 of 1000\n",
      "954 of 1000\n",
      "955 of 1000\n",
      "956 of 1000\n",
      "957 of 1000\n",
      "958 of 1000\n",
      "959 of 1000\n",
      "960 of 1000\n",
      "961 of 1000\n",
      "962 of 1000\n",
      "963 of 1000\n",
      "964 of 1000\n",
      "965 of 1000\n",
      "966 of 1000\n",
      "967 of 1000\n",
      "968 of 1000\n",
      "969 of 1000\n",
      "970 of 1000\n",
      "971 of 1000\n",
      "972 of 1000\n",
      "973 of 1000\n",
      "974 of 1000\n",
      "975 of 1000\n",
      "976 of 1000\n",
      "977 of 1000\n",
      "978 of 1000\n",
      "979 of 1000\n",
      "980 of 1000\n",
      "981 of 1000\n",
      "982 of 1000\n",
      "983 of 1000\n",
      "984 of 1000\n",
      "985 of 1000\n",
      "986 of 1000\n",
      "987 of 1000\n",
      "988 of 1000\n",
      "989 of 1000\n",
      "990 of 1000\n",
      "991 of 1000\n",
      "992 of 1000\n",
      "993 of 1000\n",
      "994 of 1000\n",
      "995 of 1000\n",
      "996 of 1000\n",
      "997 of 1000\n",
      "998 of 1000\n",
      "999 of 1000\n"
     ]
    }
   ],
   "source": [
    "output_dict = [None] * len(df)\n",
    "\n",
    "max_input_lyrics = 8        # number of lines of the song's lyrics to pass to the model\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "\n",
    "    print(f\"{i} of {len(df)}\")\n",
    "    \n",
    "    lyric_lines = row.lyrics.split(\"\\n\")\n",
    "\n",
    "    # if the song has fewer than max_input_lyrics,\n",
    "    # then use all but the last line of the lyrics\n",
    "    # in the input prompt\n",
    "    num_lyric_lines = max_input_lyrics\n",
    "    if len(lyric_lines) < max_input_lyrics + 1:\n",
    "         num_lyric_lines = len(lyric_lines) - 1\n",
    "\n",
    "    # calculate the maximum number of words contained\n",
    "    # in each line of the song's lyrics -- we'll pass\n",
    "    # this to the model as the maximum number of new\n",
    "    # tokens to generate\n",
    "    num_words = [len(x.split(\" \")) for x in lyric_lines]\n",
    "    max_words = int(np.max([20, np.max(num_words)]))\n",
    "\n",
    "    snippet = \"\\n\".join(lyric_lines[0:num_lyric_lines])\n",
    "    reference = lyric_lines[num_lyric_lines]\n",
    "\n",
    "    # the baseline T5 model has a task prefix of \"summarize:\"\n",
    "    # for text generation\n",
    "    baseline_prompt = \"summarize: \" + snippet\n",
    "\n",
    "    # tokenize the input\n",
    "    baseline_input_tokens = baseline_tokenizer(\n",
    "        baseline_prompt,\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    # generate the output tokens\n",
    "    baseline_output_tokens = baseline_model.generate(\n",
    "        baseline_input_tokens[\"input_ids\"],\n",
    "        max_new_tokens=max_words,\n",
    "        num_beams=2,\n",
    "        repetition_penalty=1.2\n",
    "    )\n",
    "\n",
    "    # convert the output to a text string\n",
    "    baseline_output = \"\".join(\n",
    "        baseline_tokenizer.batch_decode(\n",
    "            baseline_output_tokens,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # repeat the steps above for the finetuned model,\n",
    "    # which uses a different task prefix\n",
    "    finetuned_prompt = \"write next line for: \" + snippet\n",
    "\n",
    "    finetuned_input_tokens = finetuned_tokenizer(\n",
    "        finetuned_prompt,\n",
    "        max_length=max_length,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "\n",
    "    finetuned_output_tokens = finetuned_model.generate(\n",
    "        finetuned_input_tokens[\"input_ids\"],\n",
    "        max_new_tokens=max_words,\n",
    "        num_beams=2,\n",
    "        repetition_penalty=1.2\n",
    "    )\n",
    "\n",
    "    finetuned_output = \"\".join(\n",
    "        finetuned_tokenizer.batch_decode(\n",
    "            finetuned_output_tokens,\n",
    "            skip_special_tokens=True,\n",
    "            clean_up_tokenization_spaces=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # store the results to the output dictionary array\n",
    "    output_dict[i] = {\n",
    "        \"song_id\" : row.id,\n",
    "        \"input\" : snippet,\n",
    "        \"reference\" : reference,\n",
    "        \"baseline_output\" : baseline_output,\n",
    "        \"finetuned_output\" : finetuned_output\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GM6emnMfoxeD",
   "metadata": {
    "id": "GM6emnMfoxeD"
   },
   "source": [
    "# Convert Output Dictionary to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0965e47a",
   "metadata": {
    "id": "0965e47a",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>song_id</th>\n",
       "      <th>input</th>\n",
       "      <th>reference</th>\n",
       "      <th>baseline_output</th>\n",
       "      <th>finetuned_output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6728186</td>\n",
       "      <td>Pick one of my random memories\\nI can precisel...</td>\n",
       "      <td>I need to live and forget</td>\n",
       "      <td>pick one of my random memories i can precisely...</td>\n",
       "      <td>It's hard sometimes not to be able to forget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5057485</td>\n",
       "      <td>It's October\\nThe leaves are falling down, fal...</td>\n",
       "      <td>Listen to me</td>\n",
       "      <td>it's October The leaves are falling down, fall...</td>\n",
       "      <td>Is this just a dream, is this just a dream?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7128594</td>\n",
       "      <td>Well, you don't like my smoking\\nYou don't lik...</td>\n",
       "      <td>Try a tiny bit of crazy, I'll try to toe the line</td>\n",
       "      <td>i like a lot, you like a little Let's take a s...</td>\n",
       "      <td>Let's take a shot and we can meet in the middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194843</td>\n",
       "      <td>Completely complacent\\nSo excitedly vacant\\nI ...</td>\n",
       "      <td>Baby its a fine line</td>\n",
       "      <td>completely complacent so excitedly vacant i ke...</td>\n",
       "      <td>You call this comfortably normal but i call it...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7764202</td>\n",
       "      <td>Feels like home doesn’t look right\\nThe truth ...</td>\n",
       "      <td>Forgive me love, forgive me love</td>\n",
       "      <td>ain’t it funny how things you tell yourself Re...</td>\n",
       "      <td>Can you forgive me love, forgive me love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>5636396</td>\n",
       "      <td>Take your hands off me\\nI'm beyond your touch\\...</td>\n",
       "      <td>Love is so good, so good</td>\n",
       "      <td>take your hands off me i'm beyond your touch a...</td>\n",
       "      <td>I'm dancing with the demon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>7333221</td>\n",
       "      <td>Every child put down your toys\\nAnd come insid...</td>\n",
       "      <td>Climate denying</td>\n",
       "      <td>every child put down your toys and come inside...</td>\n",
       "      <td>Temperature rising</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1024796</td>\n",
       "      <td>Light up the room with a little more light\\nI ...</td>\n",
       "      <td>Can’t decide, Gaga or Bieber?</td>\n",
       "      <td>pot commited is a new album from the british s...</td>\n",
       "      <td>Yellow or pink?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>6785137</td>\n",
       "      <td>I don’t what the world is coming to\\nEverythin...</td>\n",
       "      <td>There is never gonna be a bright side</td>\n",
       "      <td>i don’t what the world is coming to everything...</td>\n",
       "      <td>I don’t like the way things turn around here</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>3540265</td>\n",
       "      <td>I'm laying around\\nMy head on the ground\\nI fe...</td>\n",
       "      <td>There's something here, oh</td>\n",
       "      <td>i feel like i'm sinking in i'm walking around ...</td>\n",
       "      <td>I'm laying around</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     song_id                                              input  \\\n",
       "0    6728186  Pick one of my random memories\\nI can precisel...   \n",
       "1    5057485  It's October\\nThe leaves are falling down, fal...   \n",
       "2    7128594  Well, you don't like my smoking\\nYou don't lik...   \n",
       "3     194843  Completely complacent\\nSo excitedly vacant\\nI ...   \n",
       "4    7764202  Feels like home doesn’t look right\\nThe truth ...   \n",
       "..       ...                                                ...   \n",
       "995  5636396  Take your hands off me\\nI'm beyond your touch\\...   \n",
       "996  7333221  Every child put down your toys\\nAnd come insid...   \n",
       "997  1024796  Light up the room with a little more light\\nI ...   \n",
       "998  6785137  I don’t what the world is coming to\\nEverythin...   \n",
       "999  3540265  I'm laying around\\nMy head on the ground\\nI fe...   \n",
       "\n",
       "                                             reference  \\\n",
       "0                            I need to live and forget   \n",
       "1                                         Listen to me   \n",
       "2    Try a tiny bit of crazy, I'll try to toe the line   \n",
       "3                                 Baby its a fine line   \n",
       "4                     Forgive me love, forgive me love   \n",
       "..                                                 ...   \n",
       "995                           Love is so good, so good   \n",
       "996                                    Climate denying   \n",
       "997                      Can’t decide, Gaga or Bieber?   \n",
       "998              There is never gonna be a bright side   \n",
       "999                         There's something here, oh   \n",
       "\n",
       "                                       baseline_output  \\\n",
       "0    pick one of my random memories i can precisely...   \n",
       "1    it's October The leaves are falling down, fall...   \n",
       "2    i like a lot, you like a little Let's take a s...   \n",
       "3    completely complacent so excitedly vacant i ke...   \n",
       "4    ain’t it funny how things you tell yourself Re...   \n",
       "..                                                 ...   \n",
       "995  take your hands off me i'm beyond your touch a...   \n",
       "996  every child put down your toys and come inside...   \n",
       "997  pot commited is a new album from the british s...   \n",
       "998  i don’t what the world is coming to everything...   \n",
       "999  i feel like i'm sinking in i'm walking around ...   \n",
       "\n",
       "                                      finetuned_output  \n",
       "0         It's hard sometimes not to be able to forget  \n",
       "1          Is this just a dream, is this just a dream?  \n",
       "2      Let's take a shot and we can meet in the middle  \n",
       "3    You call this comfortably normal but i call it...  \n",
       "4             Can you forgive me love, forgive me love  \n",
       "..                                                 ...  \n",
       "995                         I'm dancing with the demon  \n",
       "996                                 Temperature rising  \n",
       "997                                    Yellow or pink?  \n",
       "998       I don’t like the way things turn around here  \n",
       "999                                  I'm laying around  \n",
       "\n",
       "[1000 rows x 5 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame(output_dict)\n",
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "851cba03",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df.to_csv(\"t5_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5jY7shXVo1xh",
   "metadata": {
    "id": "5jY7shXVo1xh"
   },
   "source": [
    "# Calculate rouge and bleu Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0459560a",
   "metadata": {
    "id": "0459560a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>bleu</th>\n",
       "      <th>rouge1</th>\n",
       "      <th>rouge2</th>\n",
       "      <th>rougeL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>baseline</td>\n",
       "      <td>0.020612</td>\n",
       "      <td>0.117941</td>\n",
       "      <td>0.036777</td>\n",
       "      <td>0.107551</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>finetuned</td>\n",
       "      <td>0.066825</td>\n",
       "      <td>0.173543</td>\n",
       "      <td>0.083240</td>\n",
       "      <td>0.166543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       model      bleu    rouge1    rouge2    rougeL\n",
       "0   baseline  0.020612  0.117941  0.036777  0.107551\n",
       "1  finetuned  0.066825  0.173543  0.083240  0.166543"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge = evaluate.load(\"rouge\")\n",
    "bleu = evaluate.load(\"bleu\")\n",
    "\n",
    "baseline_rouge_scores = rouge.compute(\n",
    "    predictions=results_df[\"baseline_output\"],\n",
    "    references=results_df[\"reference\"]\n",
    ")\n",
    "\n",
    "baseline_bleu_scores = bleu.compute(\n",
    "    predictions=results_df[\"baseline_output\"],\n",
    "    references=results_df[\"reference\"]\n",
    ")\n",
    "\n",
    "finetuned_rouge_scores = rouge.compute(\n",
    "    predictions=results_df[\"finetuned_output\"],\n",
    "    references=results_df[\"reference\"]\n",
    ")\n",
    "\n",
    "finetuned_bleu_scores = bleu.compute(\n",
    "    predictions=results_df[\"finetuned_output\"],\n",
    "    references=results_df[\"reference\"]\n",
    ")\n",
    "\n",
    "score_dict = [None] * 2\n",
    "score_dict[0] = {\n",
    "    \"model\" : \"baseline\",\n",
    "    \"bleu\" : baseline_bleu_scores[\"bleu\"],\n",
    "    \"rouge1\" : baseline_rouge_scores[\"rouge1\"],\n",
    "    \"rouge2\" : baseline_rouge_scores[\"rouge2\"],\n",
    "    \"rougeL\" : baseline_rouge_scores[\"rougeL\"]\n",
    "}\n",
    "score_dict[1] = {\n",
    "    \"model\" : \"finetuned\",\n",
    "    \"bleu\" : finetuned_bleu_scores[\"bleu\"],\n",
    "    \"rouge1\" : finetuned_rouge_scores[\"rouge1\"],\n",
    "    \"rouge2\" : finetuned_rouge_scores[\"rouge2\"],\n",
    "    \"rougeL\" : finetuned_rouge_scores[\"rougeL\"]\n",
    "}\n",
    "\n",
    "score_df = pd.DataFrame(score_dict)\n",
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "947bd4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "score_df.to_csv(\"t5_scores.csv\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
